ifndef::imagesdir[:imagesdir: ../images]

[[section-testing]]
== Testing
Here lies a detailed description of some of the test of the application.

=== Jest tests
These tests are used to check that all what must be rendered in a component, it is really rendered.
There must be one jest test for each React component. If there is a React component named Login.js, its should be named Login.tests.js.
As many times, to test one component we need others, we must to mock the responses from Gateway, using axios. 

=== End-to-End tests
End-to-End tests are commonly known as e2e tests and are used to simulate the user interaction with the application from start to finish, 
validating its overall functionality.
They are composed of two files: the "file.feature" which has written the steps that are specified in the other file "file.steps.js". They 
follow the convention of "Given-When-Then" and were done using Puppeter and Cucumber

=== Generator tests
For the generator some unitary tests were developed. There are two different types.

==== Question tests
This ones are designed to test that the questions work perfectly. This does not test whether the questions are generated properly, for that is the resposability of other tests.
They do not require to access Wikidata, since they are testing the most internal parts of our application.

==== Generator tests
This tests are designed to test each one of the specific generators (for example, CapitalGenerator, VideogameDeveloperGenerator, DirectorGenerator, etc). As opposed to the question tests, this are focused on the correct access to Wikidata and generation of the questions.
They do require to access Wikidata, since they test how our application generates the questions, which are obtained from Wikidata.

=== Load testing
For load testing two different kind of test were designed. The first ones were based on the pressencce of a high number of users, across a "long" period of time. 
On the other hand, the second ones were though with the idea of a big number of users arriving almost simmultaniously.

The first ones were designed to test the application under "normal" circunstances, while the second ones were designed with an unexpected user peak in mind.

==== Constant traffic tests
- **600 users playing as guests**: Arriving in batches of 10 users per second over 60 seconds. -> link:https://github.com/Arquisoft/wiq_en1b/files/15139283/600peopleresult.pdf[Result PDF]
- **1200 users playing as guests**: Arriving in batches of 20 users per second over 60 seconds. -> link:https://github.com/Arquisoft/wiq_en1b/files/15139356/1200peopleresult.pdf[Result PDF]
- **20 users playing normally**: Arriving in batches of 2 users per second over 10 seconds. They log in, play and check the results. -> link:https://github.com/Arquisoft/wiq_en1b/files/15139376/login.pdf[Result PDF]

==== Burst traffic tests
- **2400 users playing as guests**: Arriving in batches of 200 people per second over 12 seconds. -> link:https://github.com/Arquisoft/wiq_en1b/files/15139644/burstguest.pdf[Result PDF]
- **1200 users playing normally**: Arriving in batches of 100 people per second over 12 seconds. They log in, play and check the results. -> link:https://github.com/Arquisoft/wiq_en1b/files/15139645/burstlogin.pdf[Result PDF]

As we can see, in the first kind of testing, the percentage of successful requests is between 99 and 100%. However things change when moving into the second kind, with a success rate of 91% for the ones playing as a guest and 82% for the ones logging in. 
Despite not being such great numbers as the other ones, this still represent a lot of successes under a very stresfull situation for our application.

=== Usability testing

==== Analytical information
After performing test with various people from various age groups we were able to extract information about the times they apent in the application. As we can see, the ones below 20 years of age perform much better than expected, while the ones between 40 to 60 years performed worse.
The surprisingly good performance of the first age group might be because of the colourful and very graphical navigability of the application, which allow them to grasp every component and their inner workings really quickly. 
While this same thing might have been the bane of the older age groups, since they struggle more with the navigability and where trying to read more instead of focusing on the icons.

image::12-usability-graph-01.png["Average response times by age group"]

We can also see in which parts of the application they have spent the longest. We can see how it's pretty evenly distributted. This should come as a surprise, considering that they did play a competitive game (which are pretty short).
This is thanks to the more speedy users, which brought the average down quite significally. Since the difference between one user and another are very small in the duration of the games, but massive in the logging and set up.

image::12-usability-graph-02.png["Average time spent on each part of the application"]

A potential problem could have been the small sample size, so further tests are recommended, with a similar amount of users in each age group.